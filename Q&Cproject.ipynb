{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qu1nnD/CS290/blob/main/Q%26Cproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "YzFcY8DQlt-8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.tree import plot_tree\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statistics import mean, stdev\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shrooms = pd.read_csv(\"https://raw.githubusercontent.com/Qu1nnD/CS290/main/data/mushroom_cleaned.csv\") # categorical dataset\n",
        "StudentPerform = pd.read_csv(\"https://github.com/Charlee0616/Data-Mining/raw/main/StudentPerformanceFactors.csv\") # numerical dataset"
      ],
      "metadata": {
        "id": "F-UsfPKCTM1r"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Attribute_selection_method(dataset, target, method, classification):\n",
        "  if(method == \"classification\"): #method chosen was classification\n",
        "    features = dataset.columns[dataset.columns != target]\n",
        "    entropys=[]\n",
        "    for attribute in features:\n",
        "      entropy = 0\n",
        "      overall = len( dataset )\n",
        "      vals = dataset[attribute].unique()\n",
        "      if(classification ==\"entropy\"): #classifcation was chosen and entropy was chosen\n",
        "        for val in vals:\n",
        "          if(len(dataset[attribute].unique())<20):\n",
        "            subset_size = len(dataset[ dataset[attribute] == val ])\n",
        "            weight = subset_size / overall\n",
        "            props = dataset[ dataset[attribute] == val ][target].value_counts( normalize=True )\n",
        "            for p in props.array:\n",
        "              entropy =  entropy - weight*(p*math.log2(p))\n",
        "        else: #classification was chose and Gini was chosen\n",
        "          entropy = 0\n",
        "          left = dataset[ dataset[attribute] <= val ][ [attribute,target] ]\n",
        "          props = left[ target ].value_counts( normalize = True )\n",
        "          weight = len( left ) / overall\n",
        "          for prop in props.array:\n",
        "            entropy = entropy - weight*prop*math.log2( prop )\n",
        "          right = dataset[ dataset[attribute] > val ][ [attribute,target] ]\n",
        "          props = right[ target ].value_counts( normalize = True )\n",
        "          weight = len( right ) / overall\n",
        "          for prop in props.array:\n",
        "            entropy = entropy - weight*prop*math.log2( prop )\n",
        "          entropys.append(entropy)\n",
        "      else:\n",
        "        #for val in vals:\n",
        "          #props = dataset[ dataset[attribute] == val ][target].value_counts( normalize=True )\n",
        "          #for prop in props.array:\n",
        "        entropy = 1 - sum([prop ** 2])\n",
        "          #entropy += weight * entropy\n",
        "        entropys.append(entropy)\n",
        "    minEnt=min(entropys)\n",
        "    ind=entropys.index(minEnt)\n",
        "    return features[ind]\n",
        "  else: # method is Naive Bayes Classifier/ regressor\n",
        "    #separate by class\n",
        "    separated = {}\n",
        "    for i in range(len(dataset)):\n",
        "      vector = dataset[i]\n",
        "      class_value = vector[-1]\n",
        "      if (class_value not in separated):\n",
        "        separated[class_value] = []\n",
        "      separated[class_value].append(vector)\n",
        "\n",
        "    #Summarize statistivc\n",
        "    summaries = {}\n",
        "    for class_value, instances in separated.items():\n",
        "      summaries[class_value] = [(mean(col), stdev(col), len(col)) for col in zip(*instances)]\n",
        "\n",
        "    predictions = []\n",
        "    #put test into the method\n",
        "    for row in test:\n",
        "        total_rows = sum([summaries[label][0][2] for label in summaries])\n",
        "        probabilities = {}\n",
        "        for class_value, class_summaries in summaries.items():\n",
        "          probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
        "          for i in range(len(class_summaries)):\n",
        "            mean_val, stdev_val, _ = class_summaries[i]\n",
        "            exponent = math.exp(-((row[i]-mean_val)**2 / (2 * stdev_val**2 )))\n",
        "            probabilities[class_value] *=(1 / (math.sqrt(2 * math.pi) * stdev_val)) * exponent\n",
        "        #determine the best label\n",
        "        best_label, best_prob = None, -1\n",
        "        for class_value, probability in probabilities.items():\n",
        "          if best_label is None or probability > best_prob:\n",
        "            best_prob = probability\n",
        "            best_label = class_value\n",
        "\n",
        "        predictions.append(best_label)\n",
        "    return(predictions)"
      ],
      "metadata": {
        "id": "ef6qrqhx0CcX"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing and Training data for Shrooms dataset\n",
        "C_train_set, C_test_set = train_test_split(shrooms, test_size=0.2)\n",
        "C_train_set = C_train_set[['cap-diameter', 'cap-shape', 'gill-attachment', 'gill-color', 'stem-height', 'stem-width', 'stem-color', 'class']]\n",
        "C_test_set = C_test_set[['cap-diameter', 'cap-shape', 'gill-attachment', 'gill-color','stem-height', 'stem-width', 'stem-color', 'class']]\n",
        "C_X_train = C_train_set[['cap-diameter', 'cap-shape', 'gill-attachment', 'gill-color','stem-height', 'stem-width', 'stem-color']]\n",
        "C_y_train = C_train_set[\"class\"]\n",
        "C_X_test = C_test_set[['cap-diameter', 'cap-shape', 'gill-attachment', 'gill-color','stem-height', 'stem-width', 'stem-color']]\n",
        "C_y_test = C_test_set[\"class\"]\n",
        "cat_attributes=[]\n",
        "num_attributes=[]\n",
        "for col in C_X_train.columns:\n",
        "  if len(C_X_train[col].unique()) < 20:\n",
        "    cat_attributes.append(col)\n",
        "  else:\n",
        "    num_attributes.append(col)\n",
        "trf = [ ('num', StandardScaler(), num_attributes),\n",
        "       ('cat', OneHotEncoder( handle_unknown='ignore'), cat_attributes) ]\n",
        "col_transform = ColumnTransformer( transformers = trf )\n",
        "pipeline = Pipeline( steps = [('pre', col_transform),\n",
        " ('clf', DecisionTreeClassifier())])"
      ],
      "metadata": {
        "id": "bqq8YTsYXMaF"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_train_set, R_test_set = train_test_split(StudentPerform, test_size=0.2)\n",
        "num_attributes = R_X_train.select_dtypes( include = ['int64','float64']).columns\n",
        "R_X_train = R_train_set[num_attributes[num_attributes!=\"Exam_Score\"]]\n",
        "R_y_train = R_train_set[\"Exam_Score\"]\n",
        "R_X_test = R_test_set[num_attributes[num_attributes!=\"Exam_Score\"]]\n",
        "R_y_test = R_test_set[\"Exam_Score\"]"
      ],
      "metadata": {
        "id": "fWnyt1E5Zdwi"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical Dataset Test\n",
        "# Gini test\n",
        "Cat_G=Attribute_selection_method(shrooms,\"class\",\"classification\",\"gini\")\n",
        "Cat_G"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "nPSnUNb0SDe3",
        "outputId": "744e69b2-c8a3-4fe7-bd8d-66cad4f2bfc8"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "local variable 'prop' referenced before assignment",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-40ff8ba3de61>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Categorical Dataset Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Gini test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mCat_G\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAttribute_selection_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshrooms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"gini\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mCat_G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-0cf2a13cbac5>\u001b[0m in \u001b[0;36mAttribute_selection_method\u001b[0;34m(dataset, target, method, classification)\u001b[0m\n\u001b[1;32m     32\u001b[0m           \u001b[0;31m#props = dataset[ dataset[attribute] == val ][target].value_counts( normalize=True )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0;31m#for prop in props.array:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprop\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m           \u001b[0;31m#entropy += weight * entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mentropys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'prop' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Tree Test for comparison\n",
        "DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "6xDUCdtCbIk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorical Dataset Test\n",
        "# Entropy test\n",
        "Cat_E=Attribute_selection_method(shrooms,\"class\",\"classification\",\"entropy\")\n",
        "Cat_E"
      ],
      "metadata": {
        "id": "iZRkuoafSmAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Tree Test for comparison\n",
        "DecisionTreeClassifier('entropy')"
      ],
      "metadata": {
        "id": "evchq-X2WS1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical Dataset Test\n",
        "numT=Attribute_selection_method(StudentPerform,\"Exam_Score\",\"regression\",\"nothing\")\n",
        "numT"
      ],
      "metadata": {
        "id": "jjDFulVWSDZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regression Tree Test for comparison\n",
        "Regression_tree_model = DecisionTreeRegressor()\n",
        "Regression_tree_model.fit(R_X_train, R_y_train)\n",
        "R_y_pred_dt = Regression_tree_model.predict(R_X_test)\n",
        "print(\"Decision Tree Regressor Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(R_y_test, R_y_pred_dt):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "bOK7gFIkSDRE",
        "outputId": "8ad3cb2b-47ed-4c83-92dd-578129d401e0"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor Model Performance:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-6f634c09e1c9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mR_y_pred_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegression_tree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decision Tree Regressor Model Performance:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {accuracy_score(R_y_test, R_y_pred_dt):.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace_and_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m    114\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8aZgBIkhSDH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}